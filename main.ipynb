{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FARAKSA61iVW",
        "outputId": "1182641c-1201-4cf0-c483-1a725088e81b"
      },
      "outputs": [],
      "source": [
        "!pip install -q opendatasets tfx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UNwYpUv-1orS"
      },
      "outputs": [],
      "source": [
        "# @title Import Library\n",
        "\n",
        "import cv2,os,re, string,shutil\n",
        "import opendatasets as od\n",
        "import gdown\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tfx.components import ImportExampleGen, CsvExampleGen, StatisticsGen, SchemaGen, ExampleValidator, Transform, Trainer, Evaluator, Tuner, InfraValidator, Pusher\n",
        "from tfx.proto import example_gen_pb2, trainer_pb2, pusher_pb2\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "from tfx.dsl.components.common.resolver import Resolver\n",
        "from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import LatestBlessedModelStrategy\n",
        "from tfx.types import Channel\n",
        "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "from tfx.v1.proto import ServingSpec, TensorFlowServing, LocalDockerConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bibDUcZ3IBMz",
        "outputId": "b6ec89b8-27fc-497c-d394-d21ceb51d169"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nrWT28FKWgKaIWQsTIWj1IkDuN1F-pF2\n",
            "To: /content/kaggle.json\n",
            "100%|██████████| 65.0/65.0 [00:00<00:00, 131kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/nandhanasuresh/allergen-status-of-food-products\n",
            "Downloading allergen-status-of-food-products.zip to ./allergen-status-of-food-products\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7.66k/7.66k [00:00<00:00, 8.64MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Download dataset\n",
        "\n",
        "if not os.path.exists(\"data\" and \"modules\"):\n",
        "  os.makedirs('data')\n",
        "  os.makedirs('modules')\n",
        "\n",
        "# download kaggle\n",
        "gdown.download('https://drive.google.com/uc?id=1nrWT28FKWgKaIWQsTIWj1IkDuN1F-pF2', '/content/', quiet=False)\n",
        "od.download(\"https://www.kaggle.com/datasets/nandhanasuresh/allergen-status-of-food-products\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7627Rd59Df82"
      },
      "outputs": [],
      "source": [
        "df =  pd.read_csv(\"/content/allergen-status-of-food-products/Allergen_Status_of_Food_Products.csv\")\n",
        "df = df.dropna()\n",
        "df = df.rename(columns={'Main Ingredient':'Main_Ingredient','Fat/Oil':'Fat_Oil','Price ($)':'Price', 'Customer rating (Out of 5)':'Rating','Prediction':'is_allergen'})\n",
        "df['is_allergen']=df['is_allergen'].apply(lambda x:1 if x == 'Contains' else 0)\n",
        "df.to_csv('/content/data/data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yH7K042Jb9wo"
      },
      "outputs": [],
      "source": [
        "TRANSFORM_MODULE_FILE = \"modules/allergen_food_transform.py\"\n",
        "TUNER_MODULE_FILE = \"modules/allergen_food_tuner.py\"\n",
        "TRAINER_MODULE_FILE = \"modules/allergen_food_trainer.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUNnSoJY-JP-",
        "outputId": "68c8e6fc-1048-4edf-ab2d-b0cc6a1b4c72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing modules/allergen_food_transform.py\n"
          ]
        }
      ],
      "source": [
        "# @title transform module\n",
        "%%writefile {TRANSFORM_MODULE_FILE}\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "CATEGORICAL_FEATURES = {\n",
        "    \"Main_Ingredient\": 101,\n",
        "    \"Sweetener\":10,\n",
        "    \"Fat_Oil\":36,\n",
        "    \"Seasoning\":186,\n",
        "    \"Allergens\":40\n",
        "}\n",
        "NUMERICAL_FEATURES = [\n",
        "    \"Price\",\n",
        "    \"Rating\"\n",
        "]\n",
        "LABEL_KEY = \"is_allergen\"\n",
        "\n",
        "\n",
        "def transformed_name(key):\n",
        "    \"\"\"Renaming transformed features\"\"\"\n",
        "    return key + \"_xf\"\n",
        "\n",
        "\n",
        "def convert_num_to_one_hot(label_tensor, num_labels=2):\n",
        "    \"\"\"\n",
        "    Convert a label (0 or 1) into a one-hot vector\n",
        "    Args:\n",
        "        int: label_tensor (0 or 1)\n",
        "    Returns\n",
        "        label tensor\n",
        "    \"\"\"\n",
        "    one_hot_tensor = tf.one_hot(label_tensor, num_labels)\n",
        "    return tf.reshape(one_hot_tensor, [-1, num_labels])\n",
        "\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "    \"\"\"\n",
        "    Preprocess input features into transformed features\n",
        "\n",
        "    Args:\n",
        "        inputs: map from feature keys to raw features.\n",
        "\n",
        "    Return:\n",
        "        outputs: map from feature keys to transformed features.\n",
        "    \"\"\"\n",
        "\n",
        "    outputs = {}\n",
        "\n",
        "    for key in CATEGORICAL_FEATURES:\n",
        "        dim = CATEGORICAL_FEATURES[key]\n",
        "        int_value = tft.compute_and_apply_vocabulary(\n",
        "            inputs[key], top_k=dim + 1\n",
        "        )\n",
        "        outputs[transformed_name(key)] = convert_num_to_one_hot(\n",
        "            int_value, num_labels=dim + 1\n",
        "        )\n",
        "\n",
        "    for feature in NUMERICAL_FEATURES:\n",
        "        outputs[transformed_name(feature)] = tft.scale_to_0_1(inputs[feature])\n",
        "\n",
        "    outputs[transformed_name(LABEL_KEY)] = tf.cast(inputs[LABEL_KEY], tf.int64)\n",
        "\n",
        "    return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCvpRqNOb9U1",
        "outputId": "0a8a5c67-a9eb-40e7-f924-b3b6e6c0dc5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing modules/allergen_food_tuner.py\n"
          ]
        }
      ],
      "source": [
        "# @title Tuner module\n",
        "%%writefile {TUNER_MODULE_FILE}\n",
        "\n",
        "from typing import NamedTuple, Dict, Any\n",
        "from allergen_food_transform import (\n",
        "    CATEGORICAL_FEATURES,\n",
        "    LABEL_KEY,\n",
        "    NUMERICAL_FEATURES,\n",
        "    transformed_name,\n",
        ")\n",
        "from kerastuner import RandomSearch\n",
        "from kerastuner.engine import base_tuner\n",
        "import tensorflow as tf\n",
        "from tfx.components.trainer.fn_args_utils import FnArgs\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "TunerFnResult = NamedTuple('TunerFnResult', [('tuner', base_tuner.BaseTuner),\n",
        "                                             ('fit_kwargs', Dict[str, Any])])\n",
        "\n",
        "\n",
        "def get_model(hp):\n",
        "    \"\"\"\n",
        "    This function defines a Keras model and returns the model as a\n",
        "    Keras object.\n",
        "    Args:\n",
        "        int: hp\n",
        "    Returns\n",
        "        tensorflow model\n",
        "    \"\"\"\n",
        "\n",
        "    # one-hot categorical features\n",
        "    input_features = []\n",
        "    for key, dim in CATEGORICAL_FEATURES.items():\n",
        "        input_features.append(\n",
        "            tf.keras.Input(shape=(dim + 1,), name=transformed_name(key))\n",
        "        )\n",
        "\n",
        "    for feature in NUMERICAL_FEATURES:\n",
        "        input_features.append(\n",
        "            tf.keras.Input(shape=(1,), name=transformed_name(feature))\n",
        "        )\n",
        "\n",
        "    concatenate = tf.keras.layers.concatenate(input_features)\n",
        "    deep = tf.keras.layers.Dense(256, activation=\"relu\")(concatenate)\n",
        "    # Tuning the number of hidden layers\n",
        "    for _ in range(hp.Int('num_hidden_layers', 1, 5)):\n",
        "        deep = tf.keras.layers.Dense(units=hp.Choice('units', values=[32, 64, 128, 256]), activation='relu')(deep)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(deep)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_features, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[0.001, 0.01, 0.1])),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def gzip_reader_fn(filenames):\n",
        "    \"\"\"Loads compressed data\n",
        "    Args:\n",
        "        str: filenames\n",
        "    Returns\n",
        "        TFRecordDataset\n",
        "    \"\"\"\n",
        "    return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
        "\n",
        "\n",
        "def input_fn(file_pattern, tf_transform_output, batch_size=64):\n",
        "    \"\"\"Generates features and labels for tuning/training.\n",
        "    Args:\n",
        "        file_pattern: input tfrecord file pattern.\n",
        "        tf_transform_output: A TFTransformOutput.\n",
        "        batch_size: representing the number of consecutive elements of\n",
        "        returned dataset to combine in a single batch\n",
        "    Returns:\n",
        "        A dataset that contains (features, indices) tuple where features\n",
        "        is a dictionary of Tensors, and indices is a single Tensor of\n",
        "        label indices.\n",
        "    \"\"\"\n",
        "    transformed_feature_spec = (\n",
        "        tf_transform_output.transformed_feature_spec().copy()\n",
        "    )\n",
        "\n",
        "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "        file_pattern=file_pattern,\n",
        "        batch_size=batch_size,\n",
        "        features=transformed_feature_spec,\n",
        "        reader=gzip_reader_fn,\n",
        "        label_key=transformed_name(LABEL_KEY),\n",
        "    )\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def tuner_fn(fn_args: FnArgs) -> TunerFnResult:\n",
        "    \"\"\"This is what TFX will run\n",
        "    Args:\n",
        "        FnArgs: fn_args\n",
        "    Returns\n",
        "        TunerFnResult\n",
        "    \"\"\"\n",
        "    tuner = RandomSearch(\n",
        "        get_model,\n",
        "        objective='val_binary_accuracy',\n",
        "        max_trials=10,\n",
        "        executions_per_trial=1,\n",
        "        directory=fn_args.working_dir,\n",
        "        project_name='random_search'\n",
        "    )\n",
        "\n",
        "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
        "\n",
        "    train_set = input_fn(fn_args.train_files, tf_transform_output, 64)\n",
        "    val_set = input_fn(fn_args.eval_files, tf_transform_output, 64)\n",
        "\n",
        "    return TunerFnResult(\n",
        "        tuner=tuner,\n",
        "        fit_kwargs={\n",
        "            'x': train_set,\n",
        "            'validation_data': val_set,\n",
        "            'epochs': 3,\n",
        "            'steps_per_epoch': fn_args.train_steps,\n",
        "            'validation_steps': fn_args.eval_steps\n",
        "        }\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj3LSt0I-Yv5",
        "outputId": "1bddb081-029f-46ea-ecf6-2b0e22aa4e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing modules/allergen_food_trainer.py\n"
          ]
        }
      ],
      "source": [
        "# @title Training module\n",
        "%%writefile {TRAINER_MODULE_FILE}\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "from allergen_food_transform import (\n",
        "    CATEGORICAL_FEATURES,\n",
        "    LABEL_KEY,\n",
        "    NUMERICAL_FEATURES,\n",
        "    transformed_name,\n",
        ")\n",
        "\n",
        "\n",
        "def get_model(hp,show_summary=True):\n",
        "    \"\"\"\n",
        "    This function defines a Keras model and returns the model as a\n",
        "    Keras object.\n",
        "    \"\"\"\n",
        "\n",
        "    # one-hot categorical features\n",
        "    input_features = []\n",
        "    for key, dim in CATEGORICAL_FEATURES.items():\n",
        "        input_features.append(\n",
        "            tf.keras.Input(shape=(dim + 1,), name=transformed_name(key))\n",
        "        )\n",
        "\n",
        "    for feature in NUMERICAL_FEATURES:\n",
        "        input_features.append(\n",
        "            tf.keras.Input(shape=(1,), name=transformed_name(feature))\n",
        "        )\n",
        "\n",
        "    concatenate = tf.keras.layers.concatenate(input_features)\n",
        "    deep = tf.keras.layers.Dense(256, activation=\"relu\")(concatenate)\n",
        "    # Tuning the number of hidden layers\n",
        "    num_hidden_layers = hp.get(\n",
        "        'hidden_layers') if hp and 'hidden_layers' in hp else 1\n",
        "    for _ in range(num_hidden_layers):\n",
        "        deep = tf.keras.layers.Dense(units=32, activation='relu')(deep)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(deep)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_features, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(hp.get('learning_rate') if hp else 0.001),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "    )\n",
        "\n",
        "    if show_summary:\n",
        "        model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def gzip_reader_fn(filenames):\n",
        "    \"\"\"Loads compressed data\"\"\"\n",
        "    return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
        "\n",
        "\n",
        "def get_serve_tf_examples_fn(model, tf_transform_output):\n",
        "    \"\"\"Returns a function that parses a serialized tf.Example.\"\"\"\n",
        "\n",
        "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "\n",
        "    @tf.function\n",
        "    def serve_tf_examples_fn(serialized_tf_examples):\n",
        "        \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
        "        feature_spec = tf_transform_output.raw_feature_spec()\n",
        "        feature_spec.pop(LABEL_KEY)\n",
        "        parsed_features = tf.io.parse_example(\n",
        "            serialized_tf_examples, feature_spec\n",
        "        )\n",
        "\n",
        "        transformed_features = model.tft_layer(parsed_features)\n",
        "\n",
        "        outputs = model(transformed_features)\n",
        "        return {\"outputs\": outputs}\n",
        "\n",
        "    return serve_tf_examples_fn\n",
        "\n",
        "\n",
        "def input_fn(file_pattern, tf_transform_output, batch_size=64):\n",
        "    \"\"\"Generates features and labels for tuning/training.\n",
        "    Args:\n",
        "        file_pattern: input tfrecord file pattern.\n",
        "        tf_transform_output: A TFTransformOutput.\n",
        "        batch_size: representing the number of consecutive elements of\n",
        "        returned dataset to combine in a single batch\n",
        "    Returns:\n",
        "        A dataset that contains (features, indices) tuple where features\n",
        "        is a dictionary of Tensors, and indices is a single Tensor of\n",
        "        label indices.\n",
        "    \"\"\"\n",
        "    transformed_feature_spec = (\n",
        "        tf_transform_output.transformed_feature_spec().copy()\n",
        "    )\n",
        "\n",
        "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "        file_pattern=file_pattern,\n",
        "        batch_size=batch_size,\n",
        "        features=transformed_feature_spec,\n",
        "        reader=gzip_reader_fn,\n",
        "        label_key=transformed_name(LABEL_KEY),\n",
        "    )\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "\n",
        "\n",
        "def run_fn(fn_args):\n",
        "    \"\"\"Train the model based on given args.\n",
        "    Args:\n",
        "    fn_args: Holds args used to train the model as name/value pairs.\n",
        "    \"\"\"\n",
        "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
        "\n",
        "    train_dataset = input_fn(fn_args.train_files, tf_transform_output, 64)\n",
        "    eval_dataset = input_fn(fn_args.eval_files, tf_transform_output, 64)\n",
        "\n",
        "    hp = fn_args.hyperparameters.get(\n",
        "        'values', {}) if fn_args.hyperparameters else {}\n",
        "\n",
        "    model = get_model(hp)\n",
        "\n",
        "    log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), \"logs\")\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=log_dir, update_freq=\"batch\"\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        steps_per_epoch=fn_args.train_steps,\n",
        "        validation_data=eval_dataset,\n",
        "        validation_steps=fn_args.eval_steps,\n",
        "        callbacks=[tensorboard_callback],\n",
        "        epochs=3\n",
        "    )\n",
        "\n",
        "    signatures = {\n",
        "        \"serving_default\": get_serve_tf_examples_fn(\n",
        "            model, tf_transform_output\n",
        "        ).get_concrete_function(\n",
        "            tf.TensorSpec(shape=[None], dtype=tf.string, name=\"examples\")\n",
        "        ),\n",
        "    }\n",
        "    model.save(\n",
        "        fn_args.serving_model_dir, save_format=\"tf\", signatures=signatures\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "RJto2gWXUzML"
      },
      "outputs": [],
      "source": [
        "# @title Real Components\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cnNHVhbU2is",
        "outputId": "60b065f6-e59d-4ead-db95-64c441b00d71"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LafE1BqKG5IH",
        "outputId": "9460dd61-8bf4-43fa-a6d3-b508c007db1d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/arcive.zip'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"/content/arcive\", 'zip', \"/content\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
